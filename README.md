# ðŸ“š Personalized News Aggregator

An intelligent, AI-powered news aggregator that fetches real-time articles based on user queries and preferences, summarizes them using **RAG** (Retrieval-Augmented Generation), and filters them by region, language, and content safety.

---

## ðŸ§  Features

- âœ… AI Summarization using LLM  
- âœ… Retrieval-Augmented Generation (RAG) pipeline  
- âœ… Full user authentication (Login/Register)  
- âœ… News filtering by country/region & language  
- âœ… Summaries free from headline duplication  
- âœ… Safe content filtering (NSFW / inappropriate detection)  
- âœ… Responsive Streamlit UI with pagination  
- âœ… Personalized topic suggestions  
- âœ… Full backend/frontend integration with Ollama + local vector DB  

---

## ðŸ—‚ï¸ Project Structure

project-root/
â”œâ”€â”€ frontend/              # Streamlit frontend app
â”‚   â”œâ”€â”€ app.py             # Main Streamlit app
â”‚   â”œâ”€â”€ auth_client.py     # Handles register/login API calls
â”‚   â”œâ”€â”€ api_client.py      # Talks to backend to get news and summaries
â”‚   â”œâ”€â”€ topics.py          # Suggests topics based on query/articles
â”‚   â”œâ”€â”€ safety.py          # Simple client-side content safety check
â”‚   â”œâ”€â”€ ui.py              # Streamlit UI components (summary, articles)
â”‚   â”œâ”€â”€ settings.py        # Configurable frontend constants
â”œâ”€â”€ backend/               # Flask or FastAPI backend (assumed)
â”‚   â””â”€â”€ ...                # Handles API routing, vector DB, summarization
â”œâ”€â”€ app/                   # Core app logic
â”‚   â”œâ”€â”€ rag.py             # Full RAG pipeline: index â†’ retrieve â†’ generate
â”‚   â”œâ”€â”€ content_extractor.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â””â”€â”€ ...

## Setup Backend

The backend is responsible for fetching full articles, vector indexing, and calling the LLM.

```bash
uvicorn main:app --reload
streamlit run app.py
```

## ðŸ” Authentication

- Users can register and log in.  
- Auth token is stored in session state.  
- Logged-in users get personalized suggestions.  

---

## ðŸŒ Country & Language Filtering

- Choose a country from the sidebar.  
- Region (`us`, `in`, `de`, etc.) and language (`en`, `de`, etc.) are auto-set.  
- When **Filter by my country** is enabled, all searches will respect the selected region/lang.  

---

## ðŸ§  How Summarization Works

### ðŸ”¹ MAP Phase
For each article:
- Title + fulltext is passed to the LLM using a map prompt.  
- Extracts **3â€“5 key bullet points** (no quotes, no duplication from headline).  

### ðŸ”¹ REDUCE Phase
- Combines all bullet points into a **user-personalized summary block**.  
- JSON output includes:
  - Overall summary  
  - Highlights  
  - Top articles with link  

---

## âœ¨ Smart Display Features

- ðŸŽ¯ Only shows **3 articles per page**  
- âœ… Each article is summarized below the title  
- ðŸ“ Truncation is avoided; summary block has expanded height  
- ðŸŒ Summaries only shown in **English**, regardless of source article language  
- ðŸ›¡ï¸ NSFW/unsafe content is filtered using a basic client-side check  

---

## ðŸ§± Backend API Structure
- POST /api/news         # get_news()
- POST /api/summarize    # summarize_batch()
- POST /api/register     # register()
- POST /api/login        # login()

## ðŸš€ Tech Stack & Tools

### ðŸ§± Frameworks & Libraries
| Layer         | Tech Used                                         |
| ------------- | ------------------------------------------------- |
| Frontend      | [Streamlit](https://streamlit.io/)                |
| Backend       | [FastAPI](https://fastapi.tiangolo.com/)          |
| API Handling  | `requests`, `httpx`                               |
| Auth          | Custom auth via FastAPI + JWT                     |
| Vector DB     | In-memory (or `ChromaDB`, optional)               |
| LLM Interface | [Ollama](https://ollama.com) (local)              |

---

### ðŸ¤– Large Language Models (LLMs)
| Model     | Provider | Purpose                  |
| --------- | -------- | ------------------------ |
| `mistral` | Ollama   | Main summarization model |
| `llama3`  | Ollama   | Alternative LLM option   |

**Used for:**
- Summarizing individual articles (**MAP**)
- Generating overall summary blocks (**REDUCE**)
- Removing duplication between headlines and content
- Ensuring English-only responses

---

### ðŸ§© Embeddings
| Component       | Value                                                      |
| --------------- | ---------------------------------------------------------- |
| Model           | `nomic-embed-text`                                         |
| Provider        | Ollama (via `embed_model`)                                 |
| Chunking Method | Fixed length (900 chars) with 150 char overlap             |
| Usage           | Vector similarity for retrieval during summarization (RAG) |

---

## ðŸ” Authentication Flow

1. User registers or logs in  
2. Backend returns `user_id` and `token`  
3. Token is stored in `st.session_state`  
4. All backend requests include this token  
5. Search history and topic suggestions are tied to `user_id`  

## ðŸ”„ Flow Diagram

```text
User Query
   â†“
Fetch News Articles (Region + Lang)
   â†“
Full Article â†’ Chunk â†’ Embed â†’ Vector DB
   â†“
Query â†’ Similar Chunks Retrieved
   â†“
MAP: Summarize Each Chunk
   â†“
REDUCE: Combine Summaries + Generate Highlights
   â†“
Display Summary + Top Articles in UI
```
---
## ðŸ§ª Example Prompts (LLM)
### MAP Prompt
```text
You are a concise journalist and summarizer. From the ARTICLE below, write 3â€“5 bullet points summarizing key insights.

Rules:
- Summarize in **English** only.
- Do NOT repeat phrases or facts from the article title or link.
- Do NOT quote directly or use exact sentences from the article.
- Avoid generic openings. Be specific and insightful.
- Each bullet must be >= 100 words.
- It should be concise and also informative.
- Do not begin with the acronyms

```
### REDUCE Prompt
User preferences: {prefs}
Query: {query}
Synthesize the per-article bullets into a briefing.

Return JSON:
{"summary":"...", "highlights":[ "...", "..."], "top":[{"title":"...","link":"..."}]}
Per-article bullets:
{bullets}
Only return JSON.

ðŸŽ¬ [Demo Video](demo_video/demo_video.mov)
